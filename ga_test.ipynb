{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.genetic_algorithm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms = [\n",
    "    Room(\"B9-F1\", 60, \"normal\"),\n",
    "    Room(\"B9-F2\", 60, \"normal\"),\n",
    "    Room(\"B9-F3\", 60, \"normal\"),\n",
    "    Room(\"B9-F4\", 60, \"normal\"),\n",
    "    Room(\"B9-F5\", 60, \"normal\"),\n",
    "    Room(\"B9-F6\", 30, \"normal\"),\n",
    "    Room(\"B9-F7\", 60, \"normal\"),\n",
    "    Room(\"B9-F8\", 60, \"normal\"),\n",
    "    Room(\"B9-F9\", 60, \"normal\"),\n",
    "    Room(\"B9-F10\", 150, \"normal\"),\n",
    "    Room(\"B9-51\", 30, \"laboratories\"),\n",
    "    Room(\"B9-52\", 60, \"normal\"),\n",
    "    Room(\"B9-53\", 30, \"laboratories\"),\n",
    "    Room(\"B14-1.11\", 60, \"normal\"),\n",
    "    Room(\"B14-1.12\", 30, \"laboratories\"),\n",
    "    Room(\"B14-2.1\", 30, \"laboratories\"),\n",
    "    Room(\"B14-2.2\", 30, \"laboratories\"),\n",
    "    Room(\"B14-2.3\", 30, \"laboratories\"),\n",
    "]\n",
    "\n",
    "program = Data(\"program.xlsx\")\n",
    "\n",
    "professors = program.create_professors()\n",
    "\n",
    "courses = program.create_courses(professors)\n",
    "\n",
    "MS_sem_1_gr_1 = Students(0, 1, 1, \"matematyka stosowana\")\n",
    "MS_sem_1_gr_2 = Students(1, 1, 2, \"matematyka stosowana\")\n",
    "MS_sem_2_gr_1 = Students(2, 2, 1, \"matematyka stosowana\")\n",
    "MS_sem_2_gr_2 = Students(3, 2, 2, \"matematyka stosowana\")\n",
    "MS_sem_3_gr_1 = Students(4, 3, 1, \"matematyka stosowana\")\n",
    "MS_sem_3_gr_2 = Students(5, 3, 2, \"matematyka stosowana\")\n",
    "MS_sem_4_gr_1 = Students(6, 4, 1, \"matematyka stosowana\")\n",
    "MS_sem_4_gr_2 = Students(7, 4, 2, \"matematyka stosowana\")\n",
    "MS_sem_5_gr_1 = Students(8, 5, 1, \"matematyka stosowana\")\n",
    "MS_sem_6_gr_1 = Students(9, 6, 1, \"matematyka stosowana\")\n",
    "students = [\n",
    "    MS_sem_1_gr_1, MS_sem_1_gr_2, MS_sem_2_gr_1, MS_sem_2_gr_2,\n",
    "    MS_sem_3_gr_1, MS_sem_3_gr_2, MS_sem_4_gr_1, MS_sem_4_gr_2,\n",
    "    MS_sem_5_gr_1, MS_sem_6_gr_1, \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop1 = Population(\n",
    "    500, \n",
    "    professors, courses, rooms, students, \n",
    "    mutation_probability=0.7, \n",
    "    number_of_elites=20, \n",
    "    number_of_pairs=150,\n",
    "    number_of_swaps=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Po 1-tej iteracji najlepszy wynik fitness wynosi: 0.25.\n",
      "Po 2-tej iteracji najlepszy wynik fitness wynosi: 0.3333333333333333.\n",
      "Po 3-tej iteracji najlepszy wynik fitness wynosi: 0.3333333333333333.\n",
      "Po 4-tej iteracji najlepszy wynik fitness wynosi: 0.3333333333333333.\n",
      "Po 5-tej iteracji najlepszy wynik fitness wynosi: 0.5.\n",
      "Po 6-tej iteracji najlepszy wynik fitness wynosi: 0.5.\n",
      "Po 7-tej iteracji najlepszy wynik fitness wynosi: 0.5.\n",
      "Po 8-tej iteracji najlepszy wynik fitness wynosi: 0.5.\n",
      "Po 9-tej iteracji najlepszy wynik fitness wynosi: 0.5.\n",
      "Po 10-tej iteracji najlepszy wynik fitness wynosi: 0.5.\n",
      "Po 11-tej iteracji najlepszy wynik fitness wynosi: 0.5.\n",
      "Po 12-tej iteracji najlepszy wynik fitness wynosi: 1.0.\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "while 1.0 not in pop1.set_and_get_fitnesses():\n",
    "    pop1.genetic_cycle()\n",
    "    print(f\"Po {i}-tej iteracji najlepszy wynik fitness wynosi: {pop1.population[0].fitness}.\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Po 1-tej iteracji najlepszy wynik soft_fitness wynosi: 0.033707865168539325.\n",
      "Po 2-tej iteracji najlepszy wynik soft_fitness wynosi: 0.033707865168539325.\n",
      "Po 3-tej iteracji najlepszy wynik soft_fitness wynosi: 0.05154639175257732.\n",
      "Po 4-tej iteracji najlepszy wynik soft_fitness wynosi: 0.05154639175257732.\n",
      "Po 5-tej iteracji najlepszy wynik soft_fitness wynosi: 0.05263157894736842.\n",
      "Po 6-tej iteracji najlepszy wynik soft_fitness wynosi: 0.05263157894736842.\n",
      "Po 7-tej iteracji najlepszy wynik soft_fitness wynosi: 0.05434782608695652.\n",
      "Po 8-tej iteracji najlepszy wynik soft_fitness wynosi: 0.057692307692307696.\n",
      "Po 9-tej iteracji najlepszy wynik soft_fitness wynosi: 0.057692307692307696.\n",
      "Po 10-tej iteracji najlepszy wynik soft_fitness wynosi: 0.057692307692307696.\n",
      "Po 11-tej iteracji najlepszy wynik soft_fitness wynosi: 0.06315789473684211.\n",
      "Po 12-tej iteracji najlepszy wynik soft_fitness wynosi: 0.06315789473684211.\n",
      "Po 13-tej iteracji najlepszy wynik soft_fitness wynosi: 0.06315789473684211.\n",
      "Po 14-tej iteracji najlepszy wynik soft_fitness wynosi: 0.06315789473684211.\n",
      "Po 15-tej iteracji najlepszy wynik soft_fitness wynosi: 0.06315789473684211.\n",
      "Po 16-tej iteracji najlepszy wynik soft_fitness wynosi: 0.07446808510638298.\n",
      "Po 17-tej iteracji najlepszy wynik soft_fitness wynosi: 0.07446808510638298.\n",
      "Po 18-tej iteracji najlepszy wynik soft_fitness wynosi: 0.07446808510638298.\n",
      "Po 19-tej iteracji najlepszy wynik soft_fitness wynosi: 0.07446808510638298.\n",
      "Po 20-tej iteracji najlepszy wynik soft_fitness wynosi: 0.07446808510638298.\n",
      "Po 21-tej iteracji najlepszy wynik soft_fitness wynosi: 0.07446808510638298.\n",
      "Po 22-tej iteracji najlepszy wynik soft_fitness wynosi: 0.07446808510638298.\n",
      "Po 23-tej iteracji najlepszy wynik soft_fitness wynosi: 0.08080808080808081.\n",
      "Po 24-tej iteracji najlepszy wynik soft_fitness wynosi: 0.08080808080808081.\n",
      "Po 25-tej iteracji najlepszy wynik soft_fitness wynosi: 0.08080808080808081.\n",
      "Po 26-tej iteracji najlepszy wynik soft_fitness wynosi: 0.08080808080808081.\n",
      "Po 27-tej iteracji najlepszy wynik soft_fitness wynosi: 0.08080808080808081.\n",
      "Po 28-tej iteracji najlepszy wynik soft_fitness wynosi: 0.08080808080808081.\n",
      "Po 29-tej iteracji najlepszy wynik soft_fitness wynosi: 0.08080808080808081.\n",
      "Po 30-tej iteracji najlepszy wynik soft_fitness wynosi: 0.08163265306122448.\n",
      "Po 31-tej iteracji najlepszy wynik soft_fitness wynosi: 0.08247422680412371.\n",
      "Po 32-tej iteracji najlepszy wynik soft_fitness wynosi: 0.08333333333333333.\n",
      "Po 33-tej iteracji najlepszy wynik soft_fitness wynosi: 0.08333333333333333.\n",
      "Po 34-tej iteracji najlepszy wynik soft_fitness wynosi: 0.08333333333333333.\n",
      "Po 35-tej iteracji najlepszy wynik soft_fitness wynosi: 0.08602150537634409.\n",
      "Po 36-tej iteracji najlepszy wynik soft_fitness wynosi: 0.08602150537634409.\n",
      "Po 37-tej iteracji najlepszy wynik soft_fitness wynosi: 0.08602150537634409.\n",
      "Po 38-tej iteracji najlepszy wynik soft_fitness wynosi: 0.08602150537634409.\n",
      "Po 39-tej iteracji najlepszy wynik soft_fitness wynosi: 0.08602150537634409.\n",
      "Po 40-tej iteracji najlepszy wynik soft_fitness wynosi: 0.09473684210526316.\n",
      "Po 41-tej iteracji najlepszy wynik soft_fitness wynosi: 0.09473684210526316.\n",
      "Po 42-tej iteracji najlepszy wynik soft_fitness wynosi: 0.09473684210526316.\n",
      "Po 43-tej iteracji najlepszy wynik soft_fitness wynosi: 0.09473684210526316.\n",
      "Po 44-tej iteracji najlepszy wynik soft_fitness wynosi: 0.09473684210526316.\n",
      "Po 45-tej iteracji najlepszy wynik soft_fitness wynosi: 0.09473684210526316.\n",
      "Po 46-tej iteracji najlepszy wynik soft_fitness wynosi: 0.09473684210526316.\n",
      "Po 47-tej iteracji najlepszy wynik soft_fitness wynosi: 0.09473684210526316.\n",
      "Po 48-tej iteracji najlepszy wynik soft_fitness wynosi: 0.09473684210526316.\n",
      "Po 49-tej iteracji najlepszy wynik soft_fitness wynosi: 0.09473684210526316.\n",
      "Po 50-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10416666666666667.\n",
      "Po 51-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10416666666666667.\n",
      "Po 52-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10416666666666667.\n",
      "Po 53-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10416666666666667.\n",
      "Po 54-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10416666666666667.\n",
      "Po 55-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10416666666666667.\n",
      "Po 56-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10416666666666667.\n",
      "Po 57-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10416666666666667.\n",
      "Po 58-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10416666666666667.\n",
      "Po 59-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10416666666666667.\n",
      "Po 60-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10416666666666667.\n",
      "Po 61-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10416666666666667.\n",
      "Po 62-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10416666666666667.\n",
      "Po 63-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10416666666666667.\n",
      "Po 64-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10526315789473684.\n",
      "Po 65-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10638297872340426.\n",
      "Po 66-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10638297872340426.\n",
      "Po 67-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10638297872340426.\n",
      "Po 68-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10638297872340426.\n",
      "Po 69-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10638297872340426.\n",
      "Po 70-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10638297872340426.\n",
      "Po 71-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10869565217391304.\n",
      "Po 72-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10989010989010989.\n",
      "Po 73-tej iteracji najlepszy wynik soft_fitness wynosi: 0.10989010989010989.\n",
      "Po 74-tej iteracji najlepszy wynik soft_fitness wynosi: 0.1111111111111111.\n",
      "Po 75-tej iteracji najlepszy wynik soft_fitness wynosi: 0.11578947368421053.\n",
      "Po 76-tej iteracji najlepszy wynik soft_fitness wynosi: 0.11578947368421053.\n",
      "Po 77-tej iteracji najlepszy wynik soft_fitness wynosi: 0.11578947368421053.\n",
      "Po 78-tej iteracji najlepszy wynik soft_fitness wynosi: 0.11578947368421053.\n",
      "Po 79-tej iteracji najlepszy wynik soft_fitness wynosi: 0.12087912087912088.\n",
      "Po 80-tej iteracji najlepszy wynik soft_fitness wynosi: 0.12087912087912088.\n",
      "Po 81-tej iteracji najlepszy wynik soft_fitness wynosi: 0.12087912087912088.\n",
      "Po 82-tej iteracji najlepszy wynik soft_fitness wynosi: 0.12222222222222222.\n",
      "Po 83-tej iteracji najlepszy wynik soft_fitness wynosi: 0.12222222222222222.\n",
      "Po 84-tej iteracji najlepszy wynik soft_fitness wynosi: 0.12222222222222222.\n",
      "Po 85-tej iteracji najlepszy wynik soft_fitness wynosi: 0.12222222222222222.\n",
      "Po 86-tej iteracji najlepszy wynik soft_fitness wynosi: 0.12222222222222222.\n",
      "Po 87-tej iteracji najlepszy wynik soft_fitness wynosi: 0.12359550561797752.\n",
      "Po 88-tej iteracji najlepszy wynik soft_fitness wynosi: 0.12359550561797752.\n",
      "Po 89-tej iteracji najlepszy wynik soft_fitness wynosi: 0.12359550561797752.\n",
      "Po 90-tej iteracji najlepszy wynik soft_fitness wynosi: 0.12359550561797752.\n",
      "Po 91-tej iteracji najlepszy wynik soft_fitness wynosi: 0.12359550561797752.\n",
      "Po 92-tej iteracji najlepszy wynik soft_fitness wynosi: 0.12359550561797752.\n",
      "Po 93-tej iteracji najlepszy wynik soft_fitness wynosi: 0.125.\n",
      "Po 94-tej iteracji najlepszy wynik soft_fitness wynosi: 0.13186813186813187.\n",
      "Po 95-tej iteracji najlepszy wynik soft_fitness wynosi: 0.13186813186813187.\n",
      "Po 96-tej iteracji najlepszy wynik soft_fitness wynosi: 0.13186813186813187.\n",
      "Po 97-tej iteracji najlepszy wynik soft_fitness wynosi: 0.13186813186813187.\n",
      "Po 98-tej iteracji najlepszy wynik soft_fitness wynosi: 0.13186813186813187.\n",
      "Po 99-tej iteracji najlepszy wynik soft_fitness wynosi: 0.13793103448275862.\n",
      "Po 100-tej iteracji najlepszy wynik soft_fitness wynosi: 0.13793103448275862.\n",
      "Po 101-tej iteracji najlepszy wynik soft_fitness wynosi: 0.13793103448275862.\n",
      "Po 102-tej iteracji najlepszy wynik soft_fitness wynosi: 0.13793103448275862.\n",
      "Po 103-tej iteracji najlepszy wynik soft_fitness wynosi: 0.13793103448275862.\n",
      "Po 104-tej iteracji najlepszy wynik soft_fitness wynosi: 0.13793103448275862.\n",
      "Po 105-tej iteracji najlepszy wynik soft_fitness wynosi: 0.14444444444444443.\n",
      "Po 106-tej iteracji najlepszy wynik soft_fitness wynosi: 0.14444444444444443.\n",
      "Po 107-tej iteracji najlepszy wynik soft_fitness wynosi: 0.14444444444444443.\n",
      "Po 108-tej iteracji najlepszy wynik soft_fitness wynosi: 0.14814814814814814.\n",
      "Po 109-tej iteracji najlepszy wynik soft_fitness wynosi: 0.14814814814814814.\n",
      "Po 110-tej iteracji najlepszy wynik soft_fitness wynosi: 0.14814814814814814.\n",
      "Po 111-tej iteracji najlepszy wynik soft_fitness wynosi: 0.14814814814814814.\n",
      "Po 112-tej iteracji najlepszy wynik soft_fitness wynosi: 0.14814814814814814.\n",
      "Po 113-tej iteracji najlepszy wynik soft_fitness wynosi: 0.14814814814814814.\n",
      "Po 114-tej iteracji najlepszy wynik soft_fitness wynosi: 0.15.\n",
      "Po 115-tej iteracji najlepszy wynik soft_fitness wynosi: 0.15.\n",
      "Po 116-tej iteracji najlepszy wynik soft_fitness wynosi: 0.15.\n",
      "Po 117-tej iteracji najlepszy wynik soft_fitness wynosi: 0.15.\n",
      "Po 118-tej iteracji najlepszy wynik soft_fitness wynosi: 0.15.\n",
      "Po 119-tej iteracji najlepszy wynik soft_fitness wynosi: 0.15476190476190477.\n",
      "Po 120-tej iteracji najlepszy wynik soft_fitness wynosi: 0.15476190476190477.\n",
      "Po 121-tej iteracji najlepszy wynik soft_fitness wynosi: 0.15476190476190477.\n",
      "Po 122-tej iteracji najlepszy wynik soft_fitness wynosi: 0.1625.\n",
      "Po 123-tej iteracji najlepszy wynik soft_fitness wynosi: 0.1625.\n",
      "Po 124-tej iteracji najlepszy wynik soft_fitness wynosi: 0.16666666666666666.\n",
      "Po 125-tej iteracji najlepszy wynik soft_fitness wynosi: 0.16666666666666666.\n",
      "Po 126-tej iteracji najlepszy wynik soft_fitness wynosi: 0.16666666666666666.\n",
      "Po 127-tej iteracji najlepszy wynik soft_fitness wynosi: 0.16666666666666666.\n",
      "Po 128-tej iteracji najlepszy wynik soft_fitness wynosi: 0.16666666666666666.\n",
      "Po 129-tej iteracji najlepszy wynik soft_fitness wynosi: 0.16666666666666666.\n",
      "Po 130-tej iteracji najlepszy wynik soft_fitness wynosi: 0.17333333333333334.\n",
      "Po 131-tej iteracji najlepszy wynik soft_fitness wynosi: 0.17333333333333334.\n",
      "Po 132-tej iteracji najlepszy wynik soft_fitness wynosi: 0.17333333333333334.\n",
      "Po 133-tej iteracji najlepszy wynik soft_fitness wynosi: 0.17333333333333334.\n",
      "Po 134-tej iteracji najlepszy wynik soft_fitness wynosi: 0.17333333333333334.\n",
      "Po 135-tej iteracji najlepszy wynik soft_fitness wynosi: 0.17333333333333334.\n",
      "Po 136-tej iteracji najlepszy wynik soft_fitness wynosi: 0.17333333333333334.\n",
      "Po 137-tej iteracji najlepszy wynik soft_fitness wynosi: 0.17567567567567569.\n",
      "Po 138-tej iteracji najlepszy wynik soft_fitness wynosi: 0.17567567567567569.\n",
      "Po 139-tej iteracji najlepszy wynik soft_fitness wynosi: 0.17567567567567569.\n",
      "Po 140-tej iteracji najlepszy wynik soft_fitness wynosi: 0.17567567567567569.\n",
      "Po 141-tej iteracji najlepszy wynik soft_fitness wynosi: 0.17567567567567569.\n",
      "Po 142-tej iteracji najlepszy wynik soft_fitness wynosi: 0.17567567567567569.\n",
      "Po 143-tej iteracji najlepszy wynik soft_fitness wynosi: 0.17567567567567569.\n",
      "Po 144-tej iteracji najlepszy wynik soft_fitness wynosi: 0.18055555555555555.\n",
      "Po 145-tej iteracji najlepszy wynik soft_fitness wynosi: 0.18055555555555555.\n",
      "Po 146-tej iteracji najlepszy wynik soft_fitness wynosi: 0.18055555555555555.\n",
      "Po 147-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 148-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 149-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 150-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 151-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 152-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 153-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 154-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 155-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 156-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 157-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 158-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 159-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 160-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 161-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 162-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 163-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 164-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 165-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 166-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 167-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 168-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 169-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 170-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 171-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 172-tej iteracji najlepszy wynik soft_fitness wynosi: 0.19718309859154928.\n",
      "Po 173-tej iteracji najlepszy wynik soft_fitness wynosi: 0.2028985507246377.\n",
      "Po 174-tej iteracji najlepszy wynik soft_fitness wynosi: 0.21428571428571427.\n",
      "Po 175-tej iteracji najlepszy wynik soft_fitness wynosi: 0.21428571428571427.\n",
      "Po 176-tej iteracji najlepszy wynik soft_fitness wynosi: 0.21428571428571427.\n",
      "Po 177-tej iteracji najlepszy wynik soft_fitness wynosi: 0.21428571428571427.\n",
      "Po 178-tej iteracji najlepszy wynik soft_fitness wynosi: 0.21428571428571427.\n",
      "Po 179-tej iteracji najlepszy wynik soft_fitness wynosi: 0.21428571428571427.\n",
      "Po 180-tej iteracji najlepszy wynik soft_fitness wynosi: 0.21428571428571427.\n",
      "Po 181-tej iteracji najlepszy wynik soft_fitness wynosi: 0.21428571428571427.\n",
      "Po 182-tej iteracji najlepszy wynik soft_fitness wynosi: 0.21428571428571427.\n",
      "Po 183-tej iteracji najlepszy wynik soft_fitness wynosi: 0.21428571428571427.\n",
      "Po 184-tej iteracji najlepszy wynik soft_fitness wynosi: 0.21428571428571427.\n",
      "Po 185-tej iteracji najlepszy wynik soft_fitness wynosi: 0.21428571428571427.\n",
      "Po 186-tej iteracji najlepszy wynik soft_fitness wynosi: 0.21428571428571427.\n",
      "Po 187-tej iteracji najlepszy wynik soft_fitness wynosi: 0.21428571428571427.\n",
      "Po 188-tej iteracji najlepszy wynik soft_fitness wynosi: 0.21428571428571427.\n",
      "Po 189-tej iteracji najlepszy wynik soft_fitness wynosi: 0.21428571428571427.\n",
      "Po 190-tej iteracji najlepszy wynik soft_fitness wynosi: 0.21739130434782608.\n",
      "Po 191-tej iteracji najlepszy wynik soft_fitness wynosi: 0.21739130434782608.\n",
      "Po 192-tej iteracji najlepszy wynik soft_fitness wynosi: 0.21739130434782608.\n",
      "Po 193-tej iteracji najlepszy wynik soft_fitness wynosi: 0.22058823529411764.\n",
      "Po 194-tej iteracji najlepszy wynik soft_fitness wynosi: 0.22058823529411764.\n",
      "Po 195-tej iteracji najlepszy wynik soft_fitness wynosi: 0.22058823529411764.\n",
      "Po 196-tej iteracji najlepszy wynik soft_fitness wynosi: 0.22058823529411764.\n",
      "Po 197-tej iteracji najlepszy wynik soft_fitness wynosi: 0.22058823529411764.\n",
      "Po 198-tej iteracji najlepszy wynik soft_fitness wynosi: 0.22058823529411764.\n",
      "Po 199-tej iteracji najlepszy wynik soft_fitness wynosi: 0.22388059701492538.\n",
      "Po 200-tej iteracji najlepszy wynik soft_fitness wynosi: 0.22388059701492538.\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    pop1.genetic_cycle()\n",
    "    print(f\"Po {i+1}-tej iteracji najlepszy wynik soft_fitness wynosi: {pop1.population[0].soft_fitness}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pewnie dałoby się ten wynik polepszyć, bo cały czas rósł, ale nie chciało mi się już czekać.\\\n",
    "Też warto zwrócić uwagę, że soft_fitness nie ma tak łatwej interpretacji jak zwykły fitness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop1.population = pop1.sort_by_fitness_and_soft_fitness(pop1.population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness: 1.0; soft fitness: 0.22388059701492538.\n",
      "Fitness: 1.0; soft fitness: 0.22058823529411764.\n",
      "Fitness: 1.0; soft fitness: 0.22058823529411764.\n",
      "Fitness: 1.0; soft fitness: 0.22058823529411764.\n",
      "Fitness: 1.0; soft fitness: 0.22058823529411764.\n",
      "Fitness: 1.0; soft fitness: 0.22058823529411764.\n",
      "Fitness: 1.0; soft fitness: 0.22058823529411764.\n",
      "Fitness: 1.0; soft fitness: 0.22058823529411764.\n",
      "Fitness: 1.0; soft fitness: 0.22058823529411764.\n",
      "Fitness: 1.0; soft fitness: 0.22058823529411764.\n",
      "Fitness: 1.0; soft fitness: 0.22058823529411764.\n",
      "Fitness: 1.0; soft fitness: 0.22058823529411764.\n",
      "Fitness: 1.0; soft fitness: 0.21739130434782608.\n",
      "Fitness: 1.0; soft fitness: 0.21739130434782608.\n",
      "Fitness: 1.0; soft fitness: 0.21739130434782608.\n",
      "Fitness: 1.0; soft fitness: 0.21739130434782608.\n",
      "Fitness: 1.0; soft fitness: 0.21428571428571427.\n",
      "Fitness: 1.0; soft fitness: 0.21428571428571427.\n",
      "Fitness: 1.0; soft fitness: 0.21428571428571427.\n",
      "Fitness: 1.0; soft fitness: 0.21428571428571427.\n",
      "Fitness: 1.0; soft fitness: 0.21428571428571427.\n",
      "Fitness: 1.0; soft fitness: 0.21428571428571427.\n",
      "Fitness: 1.0; soft fitness: 0.21428571428571427.\n",
      "Fitness: 1.0; soft fitness: 0.21428571428571427.\n",
      "Fitness: 1.0; soft fitness: 0.21428571428571427.\n",
      "Fitness: 1.0; soft fitness: 0.2112676056338028.\n",
      "Fitness: 1.0; soft fitness: 0.20833333333333334.\n",
      "Fitness: 1.0; soft fitness: 0.20588235294117646.\n",
      "Fitness: 1.0; soft fitness: 0.2.\n",
      "Fitness: 1.0; soft fitness: 0.19444444444444445.\n",
      "Fitness: 1.0; soft fitness: 0.19444444444444445.\n",
      "Fitness: 1.0; soft fitness: 0.18840579710144928.\n",
      "Fitness: 1.0; soft fitness: 0.18055555555555555.\n",
      "Fitness: 1.0; soft fitness: 0.17142857142857143.\n",
      "Fitness: 1.0; soft fitness: 0.15789473684210525.\n",
      "Fitness: 0.5; soft fitness: 0.21428571428571427.\n",
      "Fitness: 0.5; soft fitness: 0.21428571428571427.\n",
      "Fitness: 0.5; soft fitness: 0.21428571428571427.\n",
      "Fitness: 0.5; soft fitness: 0.21428571428571427.\n",
      "Fitness: 0.5; soft fitness: 0.21428571428571427.\n",
      "Fitness: 0.5; soft fitness: 0.21428571428571427.\n",
      "Fitness: 0.5; soft fitness: 0.2112676056338028.\n",
      "Fitness: 0.5; soft fitness: 0.2112676056338028.\n",
      "Fitness: 0.5; soft fitness: 0.2112676056338028.\n",
      "Fitness: 0.5; soft fitness: 0.20833333333333334.\n",
      "Fitness: 0.5; soft fitness: 0.20588235294117646.\n",
      "Fitness: 0.5; soft fitness: 0.2054794520547945.\n",
      "Fitness: 0.5; soft fitness: 0.2028985507246377.\n",
      "Fitness: 0.5; soft fitness: 0.19718309859154928.\n",
      "Fitness: 0.5; soft fitness: 0.19718309859154928.\n",
      "Fitness: 0.5; soft fitness: 0.1917808219178082.\n",
      "Fitness: 0.5; soft fitness: 0.1917808219178082.\n",
      "Fitness: 0.5; soft fitness: 0.19117647058823528.\n",
      "Fitness: 0.5; soft fitness: 0.1891891891891892.\n",
      "Fitness: 0.5; soft fitness: 0.18840579710144928.\n",
      "Fitness: 0.5; soft fitness: 0.18840579710144928.\n",
      "Fitness: 0.5; soft fitness: 0.18666666666666668.\n",
      "Fitness: 0.5; soft fitness: 0.18055555555555555.\n",
      "Fitness: 0.5; soft fitness: 0.1780821917808219.\n",
      "Fitness: 0.5; soft fitness: 0.1780821917808219.\n",
      "Fitness: 0.5; soft fitness: 0.1780821917808219.\n",
      "Fitness: 0.5; soft fitness: 0.17333333333333334.\n",
      "Fitness: 0.5; soft fitness: 0.16216216216216217.\n",
      "Fitness: 0.5; soft fitness: 0.15789473684210525.\n",
      "Fitness: 0.5; soft fitness: 0.15584415584415584.\n",
      "Fitness: 0.5; soft fitness: 0.1506849315068493.\n",
      "Fitness: 0.5; soft fitness: 0.14864864864864866.\n",
      "Fitness: 0.5; soft fitness: 0.14102564102564102.\n",
      "Fitness: 0.5; soft fitness: 0.12162162162162163.\n",
      "Fitness: 0.5; soft fitness: 0.10810810810810811.\n",
      "Fitness: 0.5; soft fitness: 0.09876543209876543.\n",
      "Fitness: 0.5; soft fitness: 0.0851063829787234.\n",
      "Fitness: 0.5; soft fitness: 0.030927835051546393.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.22388059701492538.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.2112676056338028.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.20833333333333334.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.20833333333333334.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.2028985507246377.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.2028985507246377.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.19718309859154928.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.19718309859154928.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.19718309859154928.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.19718309859154928.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.19117647058823528.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.1891891891891892.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.1891891891891892.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.18840579710144928.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.18840579710144928.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.18055555555555555.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.17567567567567569.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.17105263157894737.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.16901408450704225.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.16666666666666666.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.1643835616438356.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.15942028985507245.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.15789473684210525.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.14864864864864866.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.14864864864864866.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.14666666666666667.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.13924050632911392.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.1388888888888889.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.13513513513513514.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.13157894736842105.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.11688311688311688.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.11688311688311688.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.11392405063291139.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.08974358974358974.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.08450704225352113.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.07792207792207792.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.06097560975609756.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.0392156862745098.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.03225806451612903.\n",
      "Fitness: 0.3333333333333333; soft fitness: 0.010416666666666666.\n",
      "Fitness: 0.25; soft fitness: 0.20833333333333334.\n",
      "Fitness: 0.25; soft fitness: 0.20833333333333334.\n",
      "Fitness: 0.25; soft fitness: 0.2.\n",
      "Fitness: 0.25; soft fitness: 0.19736842105263158.\n",
      "Fitness: 0.25; soft fitness: 0.19718309859154928.\n",
      "Fitness: 0.25; soft fitness: 0.1891891891891892.\n",
      "Fitness: 0.25; soft fitness: 0.18571428571428572.\n",
      "Fitness: 0.25; soft fitness: 0.18309859154929578.\n",
      "Fitness: 0.25; soft fitness: 0.18055555555555555.\n",
      "Fitness: 0.25; soft fitness: 0.1780821917808219.\n",
      "Fitness: 0.25; soft fitness: 0.16901408450704225.\n",
      "Fitness: 0.25; soft fitness: 0.1643835616438356.\n",
      "Fitness: 0.25; soft fitness: 0.16216216216216217.\n",
      "Fitness: 0.25; soft fitness: 0.15584415584415584.\n",
      "Fitness: 0.25; soft fitness: 0.15584415584415584.\n",
      "Fitness: 0.25; soft fitness: 0.1527777777777778.\n",
      "Fitness: 0.25; soft fitness: 0.14666666666666667.\n",
      "Fitness: 0.25; soft fitness: 0.13513513513513514.\n",
      "Fitness: 0.25; soft fitness: 0.13157894736842105.\n",
      "Fitness: 0.25; soft fitness: 0.12987012987012986.\n",
      "Fitness: 0.25; soft fitness: 0.1282051282051282.\n",
      "Fitness: 0.25; soft fitness: 0.1232876712328767.\n",
      "Fitness: 0.25; soft fitness: 0.12.\n",
      "Fitness: 0.25; soft fitness: 0.1125.\n",
      "Fitness: 0.25; soft fitness: 0.10588235294117647.\n",
      "Fitness: 0.25; soft fitness: 0.10588235294117647.\n",
      "Fitness: 0.25; soft fitness: 0.10526315789473684.\n",
      "Fitness: 0.25; soft fitness: 0.10465116279069768.\n",
      "Fitness: 0.25; soft fitness: 0.10344827586206896.\n",
      "Fitness: 0.25; soft fitness: 0.10256410256410256.\n",
      "Fitness: 0.25; soft fitness: 0.10112359550561797.\n",
      "Fitness: 0.25; soft fitness: 0.1.\n",
      "Fitness: 0.25; soft fitness: 0.09722222222222222.\n",
      "Fitness: 0.25; soft fitness: 0.09523809523809523.\n",
      "Fitness: 0.25; soft fitness: 0.09523809523809523.\n",
      "Fitness: 0.25; soft fitness: 0.09195402298850575.\n",
      "Fitness: 0.25; soft fitness: 0.08433734939759036.\n",
      "Fitness: 0.25; soft fitness: 0.08333333333333333.\n",
      "Fitness: 0.25; soft fitness: 0.08235294117647059.\n",
      "Fitness: 0.25; soft fitness: 0.07777777777777778.\n",
      "Fitness: 0.25; soft fitness: 0.075.\n",
      "Fitness: 0.25; soft fitness: 0.07058823529411765.\n",
      "Fitness: 0.25; soft fitness: 0.07058823529411765.\n",
      "Fitness: 0.25; soft fitness: 0.06976744186046512.\n",
      "Fitness: 0.25; soft fitness: 0.0684931506849315.\n",
      "Fitness: 0.25; soft fitness: 0.06741573033707865.\n",
      "Fitness: 0.25; soft fitness: 0.05952380952380952.\n",
      "Fitness: 0.25; soft fitness: 0.05952380952380952.\n",
      "Fitness: 0.25; soft fitness: 0.04938271604938271.\n",
      "Fitness: 0.25; soft fitness: 0.046511627906976744.\n",
      "Fitness: 0.25; soft fitness: 0.043478260869565216.\n",
      "Fitness: 0.25; soft fitness: 0.043478260869565216.\n",
      "Fitness: 0.25; soft fitness: 0.038461538461538464.\n",
      "Fitness: 0.25; soft fitness: 0.03636363636363636.\n",
      "Fitness: 0.25; soft fitness: 0.03614457831325301.\n",
      "Fitness: 0.25; soft fitness: 0.033707865168539325.\n",
      "Fitness: 0.25; soft fitness: 0.03225806451612903.\n",
      "Fitness: 0.25; soft fitness: 0.030303030303030304.\n",
      "Fitness: 0.25; soft fitness: 0.03.\n",
      "Fitness: 0.25; soft fitness: 0.02830188679245283.\n",
      "Fitness: 0.25; soft fitness: 0.023529411764705882.\n",
      "Fitness: 0.25; soft fitness: 0.021052631578947368.\n",
      "Fitness: 0.2; soft fitness: 0.21428571428571427.\n",
      "Fitness: 0.2; soft fitness: 0.20833333333333334.\n",
      "Fitness: 0.2; soft fitness: 0.2054794520547945.\n",
      "Fitness: 0.2; soft fitness: 0.19718309859154928.\n",
      "Fitness: 0.2; soft fitness: 0.18571428571428572.\n",
      "Fitness: 0.2; soft fitness: 0.18309859154929578.\n",
      "Fitness: 0.2; soft fitness: 0.17567567567567569.\n",
      "Fitness: 0.2; soft fitness: 0.175.\n",
      "Fitness: 0.2; soft fitness: 0.17105263157894737.\n",
      "Fitness: 0.2; soft fitness: 0.16901408450704225.\n",
      "Fitness: 0.2; soft fitness: 0.16666666666666666.\n",
      "Fitness: 0.2; soft fitness: 0.16666666666666666.\n",
      "Fitness: 0.2; soft fitness: 0.15789473684210525.\n",
      "Fitness: 0.2; soft fitness: 0.15789473684210525.\n",
      "Fitness: 0.2; soft fitness: 0.15714285714285714.\n",
      "Fitness: 0.2; soft fitness: 0.1518987341772152.\n",
      "Fitness: 0.2; soft fitness: 0.14864864864864866.\n",
      "Fitness: 0.2; soft fitness: 0.14634146341463414.\n",
      "Fitness: 0.2; soft fitness: 0.14473684210526316.\n",
      "Fitness: 0.2; soft fitness: 0.14473684210526316.\n",
      "Fitness: 0.2; soft fitness: 0.14285714285714285.\n",
      "Fitness: 0.2; soft fitness: 0.14102564102564102.\n",
      "Fitness: 0.2; soft fitness: 0.13924050632911392.\n",
      "Fitness: 0.2; soft fitness: 0.13924050632911392.\n",
      "Fitness: 0.2; soft fitness: 0.1388888888888889.\n",
      "Fitness: 0.2; soft fitness: 0.136986301369863.\n",
      "Fitness: 0.2; soft fitness: 0.13513513513513514.\n",
      "Fitness: 0.2; soft fitness: 0.13513513513513514.\n",
      "Fitness: 0.2; soft fitness: 0.12987012987012986.\n",
      "Fitness: 0.2; soft fitness: 0.12857142857142856.\n",
      "Fitness: 0.2; soft fitness: 0.12345679012345678.\n",
      "Fitness: 0.2; soft fitness: 0.12.\n",
      "Fitness: 0.2; soft fitness: 0.11538461538461539.\n",
      "Fitness: 0.2; soft fitness: 0.11392405063291139.\n",
      "Fitness: 0.2; soft fitness: 0.1125.\n",
      "Fitness: 0.2; soft fitness: 0.10666666666666667.\n",
      "Fitness: 0.2; soft fitness: 0.10526315789473684.\n",
      "Fitness: 0.2; soft fitness: 0.1038961038961039.\n",
      "Fitness: 0.2; soft fitness: 0.0963855421686747.\n",
      "Fitness: 0.2; soft fitness: 0.09523809523809523.\n",
      "Fitness: 0.2; soft fitness: 0.09333333333333334.\n",
      "Fitness: 0.2; soft fitness: 0.09090909090909091.\n",
      "Fitness: 0.2; soft fitness: 0.08433734939759036.\n",
      "Fitness: 0.2; soft fitness: 0.08433734939759036.\n",
      "Fitness: 0.2; soft fitness: 0.08235294117647059.\n",
      "Fitness: 0.2; soft fitness: 0.08.\n",
      "Fitness: 0.2; soft fitness: 0.08.\n",
      "Fitness: 0.2; soft fitness: 0.07608695652173914.\n",
      "Fitness: 0.2; soft fitness: 0.07142857142857142.\n",
      "Fitness: 0.2; soft fitness: 0.06896551724137931.\n",
      "Fitness: 0.2; soft fitness: 0.06818181818181818.\n",
      "Fitness: 0.2; soft fitness: 0.06666666666666667.\n",
      "Fitness: 0.2; soft fitness: 0.060240963855421686.\n",
      "Fitness: 0.2; soft fitness: 0.058823529411764705.\n",
      "Fitness: 0.2; soft fitness: 0.05747126436781609.\n",
      "Fitness: 0.2; soft fitness: 0.056818181818181816.\n",
      "Fitness: 0.2; soft fitness: 0.056818181818181816.\n",
      "Fitness: 0.2; soft fitness: 0.056818181818181816.\n",
      "Fitness: 0.2; soft fitness: 0.056818181818181816.\n",
      "Fitness: 0.2; soft fitness: 0.056179775280898875.\n",
      "Fitness: 0.2; soft fitness: 0.05555555555555555.\n",
      "Fitness: 0.2; soft fitness: 0.05.\n",
      "Fitness: 0.2; soft fitness: 0.047619047619047616.\n",
      "Fitness: 0.2; soft fitness: 0.047619047619047616.\n",
      "Fitness: 0.2; soft fitness: 0.04716981132075472.\n",
      "Fitness: 0.2; soft fitness: 0.047058823529411764.\n",
      "Fitness: 0.2; soft fitness: 0.0449438202247191.\n",
      "Fitness: 0.2; soft fitness: 0.043010752688172046.\n",
      "Fitness: 0.2; soft fitness: 0.042105263157894736.\n",
      "Fitness: 0.2; soft fitness: 0.03614457831325301.\n",
      "Fitness: 0.2; soft fitness: 0.03529411764705882.\n",
      "Fitness: 0.2; soft fitness: 0.033707865168539325.\n",
      "Fitness: 0.2; soft fitness: 0.033707865168539325.\n",
      "Fitness: 0.2; soft fitness: 0.03260869565217391.\n",
      "Fitness: 0.2; soft fitness: 0.03225806451612903.\n",
      "Fitness: 0.2; soft fitness: 0.030612244897959183.\n",
      "Fitness: 0.2; soft fitness: 0.024691358024691357.\n",
      "Fitness: 0.2; soft fitness: 0.023255813953488372.\n",
      "Fitness: 0.2; soft fitness: 0.022727272727272728.\n",
      "Fitness: 0.2; soft fitness: 0.02197802197802198.\n",
      "Fitness: 0.2; soft fitness: 0.021739130434782608.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.2.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.2.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.19444444444444445.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.19444444444444445.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.19117647058823528.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.18666666666666668.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.18309859154929578.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.18309859154929578.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.18055555555555555.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.1780821917808219.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.17567567567567569.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.17567567567567569.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.17142857142857143.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.17105263157894737.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.16901408450704225.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.16666666666666666.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.16.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.16.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.15789473684210525.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.15384615384615385.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.1527777777777778.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.14285714285714285.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.14102564102564102.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.14102564102564102.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.13580246913580246.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.13513513513513514.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.13414634146341464.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.13157894736842105.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.12987012987012986.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.1282051282051282.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.1267605633802817.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.12162162162162163.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.12.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.11842105263157894.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.11764705882352941.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.11688311688311688.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.11538461538461539.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.11392405063291139.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.10975609756097561.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.10843373493975904.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.10810810810810811.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.10588235294117647.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.10294117647058823.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.09876543209876543.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.09090909090909091.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.08888888888888889.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.08602150537634409.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.08602150537634409.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.08433734939759036.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.08433734939759036.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.08333333333333333.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.08.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.08.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.07954545454545454.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.07142857142857142.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.07058823529411765.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.07058823529411765.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.06976744186046512.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.06666666666666667.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.05952380952380952.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.05952380952380952.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.056818181818181816.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.053763440860215055.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.053763440860215055.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.047058823529411764.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.043478260869565216.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.041237113402061855.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.04.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.03773584905660377.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.03333333333333333.\n",
      "Fitness: 0.16666666666666666; soft fitness: 0.030303030303030304.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.21739130434782608.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.21428571428571427.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.18571428571428572.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.18571428571428572.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.18571428571428572.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.18309859154929578.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.1794871794871795.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.1780821917808219.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.1780821917808219.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.17333333333333334.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.16883116883116883.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.16666666666666666.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.16666666666666666.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.16455696202531644.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.1643835616438356.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.1643835616438356.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.16216216216216217.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.15789473684210525.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.1527777777777778.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.1506849315068493.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.14864864864864866.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.14285714285714285.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.136986301369863.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.13513513513513514.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.13333333333333333.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.13253012048192772.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.12987012987012986.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.1282051282051282.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.12658227848101267.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.125.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.125.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.1232876712328767.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.12162162162162163.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.11764705882352941.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.11688311688311688.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.11627906976744186.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.11392405063291139.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.1111111111111111.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.1111111111111111.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.1111111111111111.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.10843373493975904.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.10714285714285714.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.10666666666666667.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.10526315789473684.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.10256410256410256.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.10126582278481013.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.10126582278481013.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.1.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.09876543209876543.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.09210526315789473.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.09090909090909091.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.09090909090909091.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.0875.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.08602150537634409.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.08235294117647059.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.08235294117647059.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.08108108108108109.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.08045977011494253.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.08045977011494253.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.07692307692307693.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.07407407407407407.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.07407407407407407.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.07368421052631578.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.06976744186046512.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.06818181818181818.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.06666666666666667.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.06493506493506493.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.06451612903225806.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.06315789473684211.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.061855670103092786.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.058823529411764705.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.05813953488372093.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.056818181818181816.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.05555555555555555.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.05333333333333334.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.05194805194805195.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.05.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.04938271604938271.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.04878048780487805.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.047058823529411764.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.046511627906976744.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.042105263157894736.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.042105263157894736.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.04081632653061224.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.04040404040404041.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.037037037037037035.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.03296703296703297.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.031914893617021274.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.029411764705882353.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.029411764705882353.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.020833333333333332.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.020618556701030927.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.018518518518518517.\n",
      "Fitness: 0.14285714285714285; soft fitness: 0.012195121951219513.\n",
      "Fitness: 0.125; soft fitness: 0.2112676056338028.\n",
      "Fitness: 0.125; soft fitness: 0.18309859154929578.\n",
      "Fitness: 0.125; soft fitness: 0.18309859154929578.\n",
      "Fitness: 0.125; soft fitness: 0.18181818181818182.\n",
      "Fitness: 0.125; soft fitness: 0.17567567567567569.\n",
      "Fitness: 0.125; soft fitness: 0.1506849315068493.\n",
      "Fitness: 0.125; soft fitness: 0.14084507042253522.\n",
      "Fitness: 0.125; soft fitness: 0.13924050632911392.\n",
      "Fitness: 0.125; soft fitness: 0.13333333333333333.\n",
      "Fitness: 0.125; soft fitness: 0.12941176470588237.\n",
      "Fitness: 0.125; soft fitness: 0.1232876712328767.\n",
      "Fitness: 0.125; soft fitness: 0.11688311688311688.\n",
      "Fitness: 0.125; soft fitness: 0.11688311688311688.\n",
      "Fitness: 0.125; soft fitness: 0.11428571428571428.\n",
      "Fitness: 0.125; soft fitness: 0.1125.\n",
      "Fitness: 0.125; soft fitness: 0.10975609756097561.\n",
      "Fitness: 0.125; soft fitness: 0.10666666666666667.\n",
      "Fitness: 0.125; soft fitness: 0.10666666666666667.\n",
      "Fitness: 0.125; soft fitness: 0.10344827586206896.\n",
      "Fitness: 0.125; soft fitness: 0.10256410256410256.\n",
      "Fitness: 0.125; soft fitness: 0.10126582278481013.\n",
      "Fitness: 0.125; soft fitness: 0.09302325581395349.\n",
      "Fitness: 0.125; soft fitness: 0.08974358974358974.\n",
      "Fitness: 0.125; soft fitness: 0.08860759493670886.\n",
      "Fitness: 0.125; soft fitness: 0.08641975308641975.\n",
      "Fitness: 0.125; soft fitness: 0.08433734939759036.\n",
      "Fitness: 0.125; soft fitness: 0.08333333333333333.\n",
      "Fitness: 0.125; soft fitness: 0.07865168539325842.\n",
      "Fitness: 0.125; soft fitness: 0.07608695652173914.\n",
      "Fitness: 0.125; soft fitness: 0.07317073170731707.\n",
      "Fitness: 0.125; soft fitness: 0.07317073170731707.\n",
      "Fitness: 0.125; soft fitness: 0.07317073170731707.\n",
      "Fitness: 0.125; soft fitness: 0.07058823529411765.\n",
      "Fitness: 0.125; soft fitness: 0.06976744186046512.\n",
      "Fitness: 0.125; soft fitness: 0.06896551724137931.\n",
      "Fitness: 0.125; soft fitness: 0.06896551724137931.\n",
      "Fitness: 0.125; soft fitness: 0.06666666666666667.\n",
      "Fitness: 0.125; soft fitness: 0.06521739130434782.\n",
      "Fitness: 0.125; soft fitness: 0.060240963855421686.\n",
      "Fitness: 0.125; soft fitness: 0.05747126436781609.\n",
      "Fitness: 0.125; soft fitness: 0.05194805194805195.\n",
      "Fitness: 0.125; soft fitness: 0.047058823529411764.\n",
      "Fitness: 0.125; soft fitness: 0.046511627906976744.\n",
      "Fitness: 0.125; soft fitness: 0.04597701149425287.\n",
      "Fitness: 0.125; soft fitness: 0.0425531914893617.\n",
      "Fitness: 0.125; soft fitness: 0.038834951456310676.\n",
      "Fitness: 0.125; soft fitness: 0.034482758620689655.\n",
      "Fitness: 0.125; soft fitness: 0.024096385542168676.\n",
      "Fitness: 0.125; soft fitness: 0.021739130434782608.\n",
      "Fitness: 0.125; soft fitness: 0.021505376344086023.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.18666666666666668.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.17567567567567569.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.1643835616438356.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.15714285714285714.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.15384615384615385.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.14473684210526316.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.14102564102564102.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.13333333333333333.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.1282051282051282.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.1282051282051282.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.12345679012345678.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.11627906976744186.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.11392405063291139.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.1111111111111111.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.10126582278481013.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.10112359550561797.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.0967741935483871.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.0963855421686747.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.0945945945945946.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.09411764705882353.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.09210526315789473.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.08974358974358974.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.08641975308641975.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.075.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.07228915662650602.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.06896551724137931.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.06666666666666667.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.06172839506172839.\n",
      "Fitness: 0.1111111111111111; soft fitness: 0.06.\n"
     ]
    }
   ],
   "source": [
    "for speciman in pop1.population:\n",
    "    print(f\"Fitness: {speciman.fitness}; soft fitness: {speciman.soft_fitness}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conflicts: 0;\n",
      "number of early hours: 23;\n",
      "number of late hours: 18;\n",
      "number of course conflicts: 10;\n",
      "number of free periods: 13;\n",
      "length of free periods: 16;\n",
      "number of free days: 15.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_schedule = pop1.population[0]\n",
    "print(f\"\"\"Number of conflicts: {best_schedule.number_of_conflicts};\n",
    "number of early hours: {best_schedule.number_of_early_hours};\n",
    "number of late hours: {best_schedule.number_of_late_hours};\n",
    "number of course conflicts: {best_schedule.number_of_course_conflicts};\n",
    "number of free periods: {best_schedule.number_of_free_periods};\n",
    "length of free periods: {best_schedule.length_of_free_periods};\n",
    "number of free days: {best_schedule.number_of_free_days}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conflicts: 2;\n",
      "number of early hours: 23;\n",
      "number of late hours: 18;\n",
      "number of course conflicts: 10;\n",
      "number of free periods: 28;\n",
      "length of free periods: 45;\n",
      "number of free days: 1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_soft_fitness = min([item.soft_fitness for item in pop1.population])\n",
    "worst_schedule = next(iter([item for item in pop1.population if item.soft_fitness == min_soft_fitness]))\n",
    "print(f\"\"\"Number of conflicts: {worst_schedule.number_of_conflicts};\n",
    "number of early hours: {worst_schedule.number_of_early_hours};\n",
    "number of late hours: {worst_schedule.number_of_late_hours};\n",
    "number of course conflicts: {worst_schedule.number_of_course_conflicts};\n",
    "number of free periods: {worst_schedule.number_of_free_periods};\n",
    "length of free periods: {worst_schedule.length_of_free_periods};\n",
    "number of free days: {worst_schedule.number_of_free_days}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej coś ewidentnie nie działa xd \\\n",
    "chyba, że działa i problem jest inny, ale to chyba zbyt duży przypadek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n",
      "early: 23; late: 18\n"
     ]
    }
   ],
   "source": [
    "for item in pop1.population:\n",
    "    print(f\"early: {item.number_of_early_hours}; late: {item.number_of_late_hours}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{23}\n",
      "{18}\n"
     ]
    }
   ],
   "source": [
    "print(set([item.number_of_early_hours for item in pop1.population]))\n",
    "print(set([item.number_of_late_hours for item in pop1.population]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop1.population[0].visualize_groups(\"plan_dla_studentow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop1.population[0].visualize_professors(\"plan_dla_profesorow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop1.population[0].visualize_rooms(\"plan_dla_pokoi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalnie wydaje mi się, że wygląda to dobrze. Jeszcze się trochę poeksperymentuje."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
